# ============================================================================
# Linode GPU Kubernetes Infrastructure Configuration
# ============================================================================
# Linode API Token is automatically read from linode-cli configuration
# No need to set it here - it will be loaded via environment variable
# To verify your token: linode-cli configure get token

# ============================================================================
# Cluster Configuration
# ============================================================================

# Cluster Name
# cluster_name_prefix = "my-cluster"  # Optional: Leave blank to use your system username

# Region
region = "us-ord" # Chicago, US

# Kubernetes Version
kubernetes_version = "1.34"

# GPU Node Configuration
# NVIDIA RTX 4000 Ada GPU x1 Small: 1 GPU, 4 vCPU, 16GB RAM, 512GB SSD
gpu_node_type  = "g2-gpu-rtx4000a1-s"
gpu_node_count = 1

# Autoscaling Configuration
autoscaler_min = 1
autoscaler_max = 5

# High Availability Control Plane
ha_control_plane = true

# Resource Tags
tags = ["lke", "gpu", "ml", "ai"]

# Security (Update with your IP ranges for production)
allowed_kubectl_ips    = ["0.0.0.0/0"]
allowed_monitoring_ips = ["0.0.0.0/0"]

# ============================================================================
# GPU Operator Configuration
# ============================================================================

# Enable GPU Operator (NVIDIA drivers and device plugin)
install_gpu_operator = true

# GPU Operator Version
gpu_operator_version = "v24.9.0"

# Enable GPU Monitoring (DCGM exporter for Prometheus)
enable_gpu_monitoring = true

# ============================================================================
# Metrics Server Configuration
# ============================================================================

# Enable Kubernetes Metrics Server (for kubectl top and HPA)
install_metrics_server = true

# ============================================================================
# Monitoring Stack Configuration
# ============================================================================

# Enable kube-prometheus-stack (Prometheus + Grafana + Alertmanager)
install_monitoring = true

# Grafana Admin Password (change in production!)
grafana_admin_password = "admin"

# Prometheus Data Retention
prometheus_retention = "15d"

# Persistent Storage Sizes
prometheus_storage_size = "50Gi"
grafana_storage_size    = "10Gi"

# ============================================================================
# Example Configurations
# ============================================================================

# Development/Testing Setup (minimal resources):
# gpu_node_count         = 1
# autoscaler_max         = 2
# install_gpu_operator   = true
# install_monitoring     = true
# prometheus_storage_size = "25Gi"

# Production AI Platform (full setup):
# gpu_node_count         = 2
# autoscaler_max         = 5
# install_gpu_operator   = true
# enable_gpu_monitoring  = true
# install_metrics_server = true
# install_monitoring     = true
# prometheus_retention   = "30d"
# prometheus_storage_size = "100Gi"
# grafana_admin_password = "your-secure-password-here"

# Security-Hardened Setup:
# allowed_kubectl_ips    = ["YOUR_IP/32"]
# allowed_monitoring_ips = ["YOUR_IP/32"]
# ha_control_plane       = true
